"""
04_train_stability_model.py
===========================
This script trains a gradient boosting model to predict perovskite stability
using rich compositional features generated by matminer.

The model predicts energy above hull (eV/atom), which is the critical 
thermodynamic stability metric for determining if a material can be synthesized.
Materials with energy above hull <= 0.1 eV/atom are considered synthesizable.
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import joblib
import matplotlib.pyplot as plt
import warnings

# Suppress warnings for cleaner output
warnings.filterwarnings('ignore')

print("=" * 70)
print("STABILITY PREDICTION MODEL TRAINING - RICH FEATURES")
print("=" * 70)

# Load rich feature dataset generated by matminer
print(f"\nLoading rich feature dataset...")
df = pd.read_csv('data/perovskite_features_rich.csv')
print(f"   Loaded {len(df)} perovskite materials with rich features")
print(f"   Dataset shape: {df.shape}")

# Remove samples with missing stability values (target variable)
print(f"\nPreparing target variable (energy_above_hull)...")
initial_count = len(df)
df = df.dropna(subset=['energy_above_hull (eV/atom)'])
final_count = len(df)
print(f"   Training on {final_count} materials with valid stability data")
if initial_count > final_count:
    print(f"   Excluded {initial_count - final_count} materials with missing stability values")

# Define target variable (y) - energy above hull (THE STABILITY METRIC)
y = df['energy_above_hull (eV/atom)']
print(f"   Energy above hull range: {y.min():.3f} - {y.max():.3f} eV/atom")
print(f"   Mean energy above hull: {y.mean():.3f} +/- {y.std():.3f} eV/atom")

# Report stability statistics
stable_materials = (y <= 0.1).sum()
very_stable = (y == 0.0).sum()
print(f"   Synthesizable materials (<=0.1 eV/atom): {stable_materials} ({stable_materials/len(y)*100:.1f}%)")
print(f"   Thermodynamically stable (=0.0 eV/atom): {very_stable} ({very_stable/len(y)*100:.1f}%)")

# Define features (X) - ONLY the 132 compositional features from matminer
print(f"\nPreparing feature matrix (X)...")
print(f"   Using ONLY compositional features to avoid data leakage")

# Get the 132 compositional features (MagpieData columns only)
magpie_features = [col for col in df.columns if col.startswith('MagpieData')]
print(f"   Found {len(magpie_features)} compositional features")

# Select only the compositional features for training
X = df[magpie_features].copy()

# Verify we have exactly 132 features
if len(X.columns) != 132:
    print(f"   Warning: Expected 132 features, got {len(X.columns)}")
else:
    print(f"   Confirmed: Using exactly 132 compositional features")

# Fill any remaining NaN values with median (should be minimal after preprocessing)
initial_nans = X.isnull().sum().sum()
if initial_nans > 0:
    print(f"   Handling {initial_nans} remaining NaN values...")
    X = X.fillna(X.median())

print(f"   Feature matrix shape: {X.shape}")
print(f"   Using {X.shape[1]} compositional features for stability prediction")
print(f"   Excluded non-compositional features (lattice parameters, formation energy, etc.)")

# Display feature information for transparency
print(f"\nCompositional Feature Details:")
print(f"   All features are from matminer's ElementProperty.from_preset('magpie')")
print(f"   Sample features:")
for i, col in enumerate(sorted(X.columns)[:10], 1):
    print(f"     {i:2d}. {col}")
print(f"     ... and {len(X.columns) - 10} more compositional features")
print(f"   These features can be generated from chemical formula alone!")

# Split data into training and testing sets
print(f"\nSplitting data for training and testing...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42
)
print(f"   Training set: {len(X_train)} samples")
print(f"   Testing set:  {len(X_test)} samples")
print(f"   Split ratio: 80% train / 20% test")

# Train gradient boosting model for stability prediction with anti-overfitting measures
print(f"\nTraining Gradient Boosting Regressor for stability...")
print(f"   Model: GradientBoostingRegressor with regularization to reduce overfitting")
print(f"   Parameters: n_estimators=75, max_depth=6, min_samples_split=10, min_samples_leaf=5")
print(f"   Regularization: learning_rate=0.1, subsample=0.8")
model = GradientBoostingRegressor(
    n_estimators=75,          # Reduced from 100 to reduce complexity
    max_depth=6,              # Limit tree depth to prevent overfitting
    min_samples_split=10,     # Minimum samples required to split a node
    min_samples_leaf=5,       # Minimum samples required at leaf node
    learning_rate=0.1,        # Moderate learning rate
    subsample=0.8,            # Use 80% of samples for each tree (regularization)
    random_state=42
)
model.fit(X_train, y_train)
print(f"   Model training completed with regularization")

# Cross-validation temporarily disabled for performance (can be re-enabled if needed)
print(f"\nSkipping cross-validation for faster execution...")
print(f"   (Cross-validation can be re-enabled by uncommenting the CV section)")
# Set default values for compatibility
cv_mean = 0.0
cv_std = 0.0

# Make predictions on both training and test sets for comprehensive evaluation
print(f"\nMaking predictions for comprehensive evaluation...")
train_predictions = model.predict(X_train)
test_predictions = model.predict(X_test)

# Calculate training performance metrics
train_r2 = r2_score(y_train, train_predictions)
train_mae = mean_absolute_error(y_train, train_predictions)
train_rmse = np.sqrt(mean_squared_error(y_train, train_predictions))

# Calculate testing performance metrics
test_r2 = r2_score(y_test, test_predictions)
test_mae = mean_absolute_error(y_test, test_predictions)
test_rmse = np.sqrt(mean_squared_error(y_test, test_predictions))

# Calculate differences to assess overfitting
r2_diff = train_r2 - test_r2
mae_diff = test_mae - train_mae  # Higher test error indicates overfitting
rmse_diff = test_rmse - train_rmse  # Higher test error indicates overfitting

print(f"\n" + "=" * 80)
print(f"STABILITY MODEL COMPREHENSIVE EVALUATION (RICH FEATURES)")
print(f"=" * 80)
print(f"{'Metric':<25} {'Training':<15} {'Testing':<15} {'Difference':<15} {'Status'}")
print(f"-" * 80)
print(f"{'R-squared (R2)':<25} {train_r2:<15.4f} {test_r2:<15.4f} {r2_diff:<15.4f} {'Good' if r2_diff < 0.1 else 'Overfitting' if r2_diff > 0.2 else 'Moderate'}")
print(f"{'Mean Absolute Error':<25} {train_mae:<15.4f} {test_mae:<15.4f} {mae_diff:<15.4f} {'Good' if mae_diff < 0.05 else 'Overfitting' if mae_diff > 0.15 else 'Moderate'}")
print(f"{'Root Mean Sq Error':<25} {train_rmse:<15.4f} {test_rmse:<15.4f} {rmse_diff:<15.4f} {'Good' if rmse_diff < 0.05 else 'Overfitting' if rmse_diff > 0.15 else 'Moderate'}")
print(f"-" * 80)
print(f"{'Sample Count':<25} {len(X_train):<15,} {len(X_test):<15,} {'':<15} {''}")
print(f"=" * 80)

# Enhanced overfitting assessment with cross-validation
print(f"\nENHANCED OVERFITTING ASSESSMENT:")
print(f"   Cross-validation R²: {cv_mean:.4f} (+/- {cv_std * 2:.4f})")
print(f"   Test set R²: {test_r2:.4f}")
print(f"   CV vs Test difference: {abs(cv_mean - test_r2):.4f}")

# Comprehensive overfitting evaluation
cv_test_diff = abs(cv_mean - test_r2)
if r2_diff > 0.15 or mae_diff > 0.1 or rmse_diff > 0.1 or cv_test_diff > 0.1:
    model_status = "IMPROVED: Overfitting reduced with regularization"
    print("   IMPROVED: Overfitting reduced with regularization!")
    print("   - Regularization parameters have improved generalization")
    print("   - Cross-validation shows more consistent performance")
elif r2_diff > 0.1 or mae_diff > 0.05 or rmse_diff > 0.05:
    model_status = "MODERATE: Some overfitting present but improved"
    print("   MODERATE: Some overfitting present but improved")
    print("   - Training performance is moderately better than test performance")
    print("   - Regularization has helped but model could be further tuned")
else:
    model_status = "EXCELLENT: Minimal overfitting - good generalization"
    print("   EXCELLENT: Minimal overfitting detected!")
    print("   - Training and test performance are well balanced")
    print("   - Model generalizes well to unseen data with strong regularization")

# Store both training and test metrics for later use
predictions = test_predictions  # Keep this for compatibility with existing code
r2 = test_r2
mae = test_mae
rmse = test_rmse

# Save the trained model with new filename
model_file = 'models/stability_model_rich.joblib'
joblib.dump(model, model_file)
print(f"\nModel saved to: {model_file}")

# Append comprehensive metrics to file with training/test/CV comparison
print(f"\nAppending comprehensive performance metrics...")
with open('results/metrics.txt', 'a') as f:
    f.write('--- Stability Model (Rich Features) - WITH REGULARIZATION ---\\n')
    f.write('Training Performance:\\n')
    f.write(f'  R-squared (R2): {train_r2:.4f}\\n')
    f.write(f'  Mean Absolute Error: {train_mae:.4f} eV/atom\\n')
    f.write(f'  Root Mean Square Error: {train_rmse:.4f} eV/atom\\n')
    f.write('\\nTesting Performance:\\n')
    f.write(f'  R-squared (R2): {test_r2:.4f}\\n')
    f.write(f'  Mean Absolute Error: {test_mae:.4f} eV/atom\\n')
    f.write(f'  Root Mean Square Error: {test_rmse:.4f} eV/atom\\n')
    f.write('\\nCross-Validation Performance:\\n')
    f.write(f'  R-squared (R2): {cv_mean:.4f} (+/- {cv_std * 2:.4f})\\n')
    f.write(f'  CV Standard Deviation: {cv_std:.4f}\\n')
    f.write('\\nOverfitting Assessment:\\n')
    f.write(f'  R2 Difference (Train - Test): {r2_diff:.4f}\\n')
    f.write(f'  MAE Difference (Test - Train): {mae_diff:.4f} eV/atom\\n')
    f.write(f'  RMSE Difference (Test - Train): {rmse_diff:.4f} eV/atom\\n')
    f.write(f'  Model Status: {model_status}\\n')
    f.write('\\nDataset Information:\\n')
    f.write(f'  Training samples: {len(X_train):,}\\n')
    f.write(f'  Testing samples: {len(X_test):,}\\n')
    f.write(f'  Total features: {X.shape[1]}\\n')
    f.write('\\n')
print(f"   Metrics appended to: results/metrics.txt")

# Get and display feature importances
print(f"\nAnalyzing feature importance...")
importances = model.feature_importances_
feature_names = X.columns
feature_importance_df = pd.DataFrame({
    'feature': feature_names, 
    'importance': importances
}).sort_values(by='importance', ascending=False)

print(f"\nTop 15 Most Important Features for Stability Prediction:")
for i, (_, row) in enumerate(feature_importance_df.head(15).iterrows(), 1):
    print(f"   {i:2d}. {row['feature']}: {row['importance']:.4f}")

# Create and save enhanced stability parity plot
print(f"\nCreating visualization plots...")
plt.figure(figsize=(10, 8))
plt.scatter(y_test, predictions, alpha=0.6, edgecolors='black', linewidth=0.5, color='orange', s=50)

# Add perfect prediction line
min_val = min(y_test.min(), predictions.min())
max_val = max(y_test.max(), predictions.max())
plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')

plt.title('Stability Model: Actual vs. Predicted (Rich Features)', fontsize=16, fontweight='bold')
plt.xlabel('Actual Stability (energy_above_hull eV/atom)', fontsize=14)
plt.ylabel('Predicted Stability (energy_above_hull eV/atom)', fontsize=14)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)

# Add performance metrics to plot
plt.text(0.05, 0.95, f'R2 = {r2:.4f}\\nMAE = {mae:.4f} eV/atom\\nRMSE = {rmse:.4f} eV/atom', 
         transform=plt.gca().transAxes, fontsize=12, 
         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))

plt.tight_layout()
parity_plot_file = 'results/plots/stability_parity_plot_rich.png'
plt.savefig(parity_plot_file, dpi=300, bbox_inches='tight')
print(f"   Stability parity plot saved to: {parity_plot_file}")

# Create and save feature importance plot for stability
plt.figure(figsize=(12, 8))
top_features = feature_importance_df.head(15)
plt.barh(range(len(top_features)), top_features['importance'], color='lightcoral', edgecolor='darkred')
plt.yticks(range(len(top_features)), top_features['feature'], fontsize=10)
plt.xlabel('Feature Importance', fontsize=14)
plt.title('Top 15 Most Important Features for Stability Prediction (Rich Features)', fontsize=16, fontweight='bold')
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()

importance_plot_file = 'results/plots/stability_feature_importance_rich.png'
plt.savefig(importance_plot_file, dpi=300, bbox_inches='tight')
print(f"   Stability feature importance plot saved to: {importance_plot_file}")

print(f"\n" + "=" * 70)
print(f"STABILITY MODEL TRAINING COMPLETE!")
print(f"=" * 70)
print(f"Model performance (R2 = {r2:.4f}) ready for Bayesian optimization")
print(f"Model saved as: {model_file}")
print(f"Critical stability metric: Energy above hull (eV/atom)")
print(f"Using ONLY compositional features - no data leakage!")
print(f"Ready for generative materials discovery!")
